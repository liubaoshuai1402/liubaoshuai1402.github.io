<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>深度学习 on BOGHTW</title>
    <link>http://localhost:1313/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 深度学习 on BOGHTW</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 20 May 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Pytorch中的张量操作</title>
      <link>http://localhost:1313/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Tue, 20 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C/</guid>
      <description>&lt;h1 id=&#34;pytorch中的张量操作&#34;&gt;Pytorch中的张量操作&lt;/h1&gt;&#xA;&lt;h2 id=&#34;数学符号&#34;&gt;数学符号&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1--运算符&#34;&gt;1. * 运算符&lt;/h3&gt;&#xA;&lt;p&gt;如果张量的形状完全一样，张量 * 张量，其实就是对应元素相乘，也可以$\odot$表示。&lt;/p&gt;&#xA;&lt;p&gt;如果张量的形状不一样，则要求他们的形状只能在一个维度上不一样，且其中一个张量这个维度的&lt;code&gt;size&lt;/code&gt;为1，这样可以用广播机制补全后相乘。&lt;/p&gt;&#xA;&lt;p&gt;如果张量 * 数字，则是全体元素乘以这个数字。&lt;/p&gt;&#xA;&lt;h2 id=&#34;函数方法&#34;&gt;函数、方法&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-permute&#34;&gt;1. &lt;code&gt;permute()&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;可以作为张量对象的方法使用，接受置换后的维度。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xD;&#xA;&#xD;&#xA;table = torch.randn(2,3,4)&#xD;&#xA;print(table)&#xD;&#xA;print(table.permute(2,1,0))&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这段代码就是将第一维和第三维进行置换。&lt;/p&gt;&#xA;&lt;p&gt;由已知的张量还有置换后的顺序，怎么写出新的张量呢，这个问题一直让我困扰。&lt;/p&gt;&#xA;&lt;img src=&#34;https://xiaoxiaobuaigugujiao.oss-cn-beijing.aliyuncs.com/img/permute.jpg&#34; style=&#34;zoom:50%;&#34; /&gt;&#xD;&#xA;&lt;p&gt;今天的学习，我脑子里突然蹦出一个邻居的概念。对于一个四维的张量元素，它应该有四个不同维度的邻居，但如果仅仅把视角局限在矩阵里，那它就只有两个邻居，一个行维度上的，一个列维度上的，这很不对。得把视野打开，通道维度和批次维度的邻居可能隔了很远，但它们也是邻居。&lt;/p&gt;&#xA;&lt;h3 id=&#34;2-reshape和view&#34;&gt;2. &lt;code&gt;reshape()&lt;/code&gt;和&lt;code&gt;view()&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;深度学习中，经常会把高维张量降维，计算后再展开，要小心翼翼，错位会带来灾难性的错误。&lt;/p&gt;&#xA;&lt;p&gt;对于一个（N，F，M）的张量，F是其特征维度。如果想把N和M合并，&lt;mark&gt;应该先把F变成最高维度或者最低维度，让需要合并的维度接壤&lt;/mark&gt;。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xD;&#xA;&#xD;&#xA;table = torch.randn(2,3,4)&#xD;&#xA;print(table)&#xD;&#xA;a = table.reshape(3,8)&#xD;&#xA;b = table.permute(1,0,2).reshape(3,8)&#xD;&#xA;&#xD;&#xA;print(a)&#xD;&#xA;print(b)&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这里先把张量形状变成了（3，2，4），再合并，可以保证张量维度不会错位，如果直接改写性质为（3，8），则会错位。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;reshape()&lt;/code&gt;和&lt;code&gt;view()&lt;/code&gt;是一样的，前者可以作用于numpy数组。&lt;/p&gt;&#xA;&lt;h3 id=&#34;3-flatten&#34;&gt;3. &lt;code&gt;flatten()&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;将高维张量展平为一维张量。&lt;/p&gt;&#xA;&lt;h3 id=&#34;4-torchcat&#34;&gt;4. &lt;code&gt;torch.cat()&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;把张量按给定的顺序和维度进行拼接，除了拼接维度外，张量必须具有相同的形状。&lt;/p&gt;&#xA;&lt;p&gt;可用于特征维度的拓展，加入新的特征。&lt;/p&gt;&#xA;&lt;h3 id=&#34;5-unsqueeze&#34;&gt;5. &lt;code&gt;unsqueeze()&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&#xA;&lt;a href=&#34;https://docs.pytorch.org/docs/stable/generated/torch.unsqueeze.html#torch.unsqueeze&#34;  target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;torch.unsqueeze&lt;/a&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;torch.unsqueeze(&lt;em&gt;input&lt;/em&gt;, &lt;em&gt;dim&lt;/em&gt;) → Tensor&lt;/p&gt;&#xA;&lt;p&gt;为张量插入一个新的&lt;code&gt;size&lt;/code&gt;为1的维度。用于升维。配合&lt;code&gt;expand()&lt;/code&gt;食用更佳。&lt;/p&gt;&#xA;&lt;h3 id=&#34;6-expand&#34;&gt;6. &lt;code&gt;expand()&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&#xA;&lt;a href=&#34;https://docs.pytorch.org/docs/stable/generated/torch.Tensor.expand.html#torch.Tensor.expand&#34;  target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;torch.Tensor.expand&lt;/a&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;这个只有张量方法，没有函数。&lt;/p&gt;</description>
    </item>
    <item>
      <title>用于搭建神经网络的函数</title>
      <link>http://localhost:1313/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch2/</link>
      <pubDate>Mon, 19 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch2/</guid>
      <description>&lt;h1 id=&#34;用于搭建神经网络的函数&#34;&gt;用于搭建神经网络的函数&lt;/h1&gt;&#xA;&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;此处记录常见的神经网络函数，排名不分先后。&lt;/p&gt;&#xA;&lt;h2 id=&#34;全连接层&#34;&gt;全连接层&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-nnlinear&#34;&gt;1. &lt;code&gt;nn.Linear()&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;对输入数据施加一个仿射线性变换，一般使用指定两个参数，是输入矩阵和输出矩阵的最高维的&lt;code&gt;size&lt;/code&gt;。（因为最高维一般是特征维度，这个函数就是用来控制特征维度&lt;code&gt;size&lt;/code&gt;大小的）&lt;/p&gt;&#xA;&lt;img src=&#34;https://xiaoxiaobuaigugujiao.oss-cn-beijing.aliyuncs.com/img/%E5%9B%BE%E5%8D%B7%E7%A7%AF.png&#34; style=&#34;zoom:50%;&#34; /&gt;&#xD;&#xA;&lt;p&gt;这里是CGCNN的图卷积操作公式，这里的W（权重），b（偏置）其实全连接层决定的。看到这样的写法就要明白其实是经历了一个全连接层。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;total_gated_fea = self.fc_full(total_nbr_fea)&#xD;&#xA;        &#xD;&#xA;total_gated_fea = self.bn1(total_gated_fea.view(&#xD;&#xA;&#x9;-1, self.atom_fea_len*2)).view(N, M, self.atom_fea_len*2)&#xD;&#xA;nbr_filter, nbr_core = total_gated_fea.chunk(2, dim=2)&#xD;&#xA;nbr_filter = self.sigmoid(nbr_filter)&#xD;&#xA;nbr_core = self.softplus1(nbr_core)&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;对应代码就是进过全连接层后，（再进行批标准化，chunk分割，这些公式里没有体现），然后施加$\sigma$函数和激活函数（g）。&lt;/p&gt;&#xA;&lt;h2 id=&#34;激活函数&#34;&gt;激活函数&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-nnrelu&#34;&gt;1. &lt;code&gt;nn.ReLU()&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;这个激活函数不用指定输入输出特征的维度，它只是把所有特征变为非负，对于正值保留原始值，对于负值则转化为0。&lt;/p&gt;&#xA;&lt;img src=&#34;https://xiaoxiaobuaigugujiao.oss-cn-beijing.aliyuncs.com/img/ReLU.png&#34;/&gt;&#xD;&#xA;&lt;h3 id=&#34;2-nnsoftmax&#34;&gt;2. &lt;code&gt;nn.Softmax()&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;对一个n维的张量施加Softmax()函数，使得其沿某个维度的元素值的和为1。所以接受一个&lt;code&gt;dim&lt;/code&gt;参数来指定维度。&#xA;&lt;/p&gt;&#xA;$$&#xD;&#xA;\mathrm{Softmax}(x_i)=\frac{\mathrm{exp}(x_i)}{\sum_{j}\mathrm{exp}(x_j)}&#xD;&#xA;$$&lt;p&gt;&#xA;这里简单插入一下Pytorch中有关&lt;code&gt;dim&lt;/code&gt;的实践。&lt;/p&gt;&#xA;&lt;p&gt;比如说一个张量的size是(4,2,3)，那么他的dim=0指的是4，dim=1指的是2，dim=2指的是3。&lt;/p&gt;&#xA;&lt;p&gt;比如说对于这个张量，我有个和Pytorch相反的习惯，我习惯先看每行有多少个元素，是3。我就误以为它的dim=0对应的是3。&lt;/p&gt;&#xA;&lt;p&gt;其实不然，深度学习中，dim最大值对应维度的size，往往对应样本的特征数。&lt;/p&gt;&#xA;&lt;p&gt;一个简单的二维的深度学习的输入张量的size一般是这样的：(batch_size,features)。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tensor([[[0.3299, 0.4336, 0.2365],&#xD;&#xA;         [0.0695, 0.0668, 0.8638]],&#xD;&#xA;&#xD;&#xA;        [[0.8114, 0.1116, 0.0770],&#xD;&#xA;         [0.3142, 0.1086, 0.5772]],&#xD;&#xA;&#xD;&#xA;        [[0.3178, 0.4508, 0.2315],&#xD;&#xA;         [0.1620, 0.2610, 0.5770]],&#xD;&#xA;&#xD;&#xA;        [[0.4454, 0.4082, 0.1464],&#xD;&#xA;         [0.2974, 0.5297, 0.1729]]])&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;3-nnlogsoftmax&#34;&gt;3. &lt;code&gt;nn.LogSoftmax()&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;对一个n维的张量施加log(Softmax())函数，通常用于获取对数概率，并与损失函数&lt;code&gt;nn.NLLLoss()&lt;/code&gt;一起使用&lt;/p&gt;</description>
    </item>
    <item>
      <title>花朵分类</title>
      <link>http://localhost:1313/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch1/</link>
      <pubDate>Sun, 18 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch1/</guid>
      <description>&lt;h1 id=&#34;花朵分类&#34;&gt;花朵分类&lt;/h1&gt;&#xA;&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;本文主要借助torchvision软件包，简单梳理一下深度学习代码的基本框架。&lt;/p&gt;&#xA;&lt;h2 id=&#34;数据集加载&#34;&gt;数据集加载&lt;/h2&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#假设当前工作路径下，存放着一个名为&#39;flower_data&#39;的文件夹，里面存放着训练集和验证集的图片&#xD;&#xA;#用os.path.join()来一级级得获取路径&#xD;&#xA;data_dir = os.path.join(os.getcwd(),&#39;flower_data&#39;)&#xD;&#xA;train_dir = os.path.join(data_dir, &#39;train&#39;)&#xD;&#xA;valid_dir = os.path.join(data_dir, &#39;valid&#39;)&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Define batch size&#xD;&#xA;batch_size = 32&#xD;&#xA;&#xD;&#xA;# Define transforms for the training and validation sets&#xD;&#xA;normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],&#xD;&#xA;                                 std=[0.229, 0.224, 0.225])&#xD;&#xA;&#xD;&#xA;#定义对数据预处理的组合，比如旋转图片、改变尺寸等等，让模型有更强的稳定性&#xD;&#xA;train_data_transforms = transforms.Compose([&#xD;&#xA;        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),&#xD;&#xA;        transforms.RandomRotation(degrees=15),&#xD;&#xA;        transforms.ColorJitter(),&#xD;&#xA;        transforms.RandomHorizontalFlip(),&#xD;&#xA;        transforms.CenterCrop(size=224),&#xD;&#xA;        transforms.ToTensor(),&#xD;&#xA;        normalize,&#xD;&#xA;    ])&#xD;&#xA;&#xD;&#xA;validate_data_transforms = transforms.Compose([&#xD;&#xA;        transforms.Resize(256),&#xD;&#xA;        transforms.CenterCrop(224),&#xD;&#xA;        transforms.ToTensor(),&#xD;&#xA;        normalize,&#xD;&#xA;    ])&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;#这里才真正的把图片加载成了二维数据。&#xD;&#xA;train_dataset = datasets.ImageFolder(&#xD;&#xA;    train_dir,&#xD;&#xA;    train_data_transforms)&#xD;&#xA;&#xD;&#xA;validate_dataset = datasets.ImageFolder(&#xD;&#xA;    valid_dir,&#xD;&#xA;    validate_data_transforms)&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;#做了那么多铺垫，其实就是为了把可用于训练的数据(二维数据)放到 DataLoader 里面&#xD;&#xA;train_loader = torch.utils.data.DataLoader(&#xD;&#xA;    train_dataset, batch_size=batch_size, shuffle=True,&#xD;&#xA;    num_workers=4)&#xD;&#xA;&#xD;&#xA;validate_loader = torch.utils.data.DataLoader(&#xD;&#xA;    validate_dataset, batch_size=batch_size, shuffle=True,&#xD;&#xA;    num_workers=4)&#xD;&#xA;&#xD;&#xA;data_loader = {}&#xD;&#xA;data_loader[&#39;train&#39;] = train_loader&#xD;&#xA;data_loader[&#39;valid&#39;] = validate_loader&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;batch_size&lt;/code&gt;，当训练数据很多时，一次性加载全部数据进行训练会是一种挑战。这时就需要用到批次训练。&lt;code&gt;batch_size&lt;/code&gt;即是一次训练中使用的数据量。注意这里的一次训练，不是指一epoch。只有遍历所有训练集后，才能叫做完成了一代训练。一代训练包含了诸多这样的一次训练。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
